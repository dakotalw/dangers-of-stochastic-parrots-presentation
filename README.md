# Dangers Of Stochastic Parrots Presentation

Presentation of "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?" for DS-5899-01 at Vanderbilt University

### Introduction

Over the past 5 years, we have been experiencing huge advances in language models, and this trend seems to only be continuing. with brand new technologies such as GPT-4 coming out just this past week. The capabilities of these new models are impressive and with the rapid improvements in capabilities of these models, it is easy to see why experts are so eager to develop and improve these models so quickly. One of the driving factors in this rapid innovation is the increased avaliability and decreased cost of computational resources that allow models to grow larger than ever and be trained on more and more data. This is represented in the following figure, showing the growth in both parameter count and training dataset size from 2019-2021.

<img src="figure1.png" alt="Figure 1" width="500">

The purpose of this paper is to highlight some of the concerns that come along with these large-scale language models, ranging from environmental concerns to the social and ethical isues that arise with LMs like these.

### Overview / Problem

Overall, I would break down the main arguments of the authors into three main concerns with large language models: environmental concerns, social bias and lack of interpretability.

Starting with the environmental concerns: 

<img src="figure1.png" alt="Figure 1" width="500">

With GPT-4 presumably having many more parameters and having been trained on significantly more data, including images, it would appear this trend is continuing.

### Authors' Suggestions

text

### Let's Talk GPT-4

The rollout of GPT-4 has only exacerbated this issue for several reasons: of course the increased size of this model, but also there has been a serious lack of transparency from OpenAI regarding GPT-4. There has been no official figure for the number of parameters or the size of the training dataset, only that we know the training data now contains images.  

### Critical Analysis

text

### Discussion Questions


We define the size of a NLP model as a combination of the number of parameters and size of training data

With the powerful new emergent technologies and improved language models, there is a trend of constantly increasing model sizes

Environmental concerns are the first consideration -  author promotes researchers reporting the costs and resources associated with their work

It is noted that those communities who often feel the most detrimental effects are often those who would experience the least benefit from LMs.

There should be more of an emphasis on publishing and understanding LMs; we want to manage hype around these models so that we are not promoting training of larger models for lofty tasks

BACKGROUND

In the sense of this paper, language models are defined by systems that are trained for string prediction tasks

Computational needs has gone down compared to some past methods such as n-gram models which use connected substrings, with technologies such as embedding being developed that significantly decrease the size of the data used


Authors promote reporting energy consumption as an evaluation metric for models


